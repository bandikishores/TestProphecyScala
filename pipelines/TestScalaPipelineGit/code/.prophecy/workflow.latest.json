{
  "metainfo" : {
    "migrationVersions" : {
      "gemBuilderVersion" : "v1"
    },
    "codeGenConfiguration" : {
      "editableConfig" : true,
      "plibVersion" : {
        "mavenVersion" : "7.1.93"
      }
    },
    "id" : "1",
    "uri" : "pipelines/TestScalaPipelineGit",
    "pipelineSettingsInfo" : {
      "applicationName" : "TestScalaPipelineGit",
      "hasApplication" : true
    },
    "language" : "scala",
    "fabricId" : "1596",
    "frontEndLanguage" : "sql",
    "mode" : "batch",
    "udfs" : {
      "language" : "scala",
      "udfs" : [ ],
      "functionPackageName" : "kishoresimpledatalabscomteam.gitbackedscala.functions",
      "sharedFunctionPackageNames" : [ "io.prophecy.scalagems.functions", "io.prophecy.warehousegems.functions" ]
    },
    "udafs" : {
      "language" : "scala",
      "code" : "package udfs\n\nimport org.apache.spark.sql.expressions._\nimport org.apache.spark.sql.types._\nimport org.apache.spark.sql._\n\n/**\n  * Here you can define your custom aggregate functions.\n  *\n  * Make sure to register your `udafs` in the register_udafs function below.\n  *\n  * Example:\n  *\n  * object GeometricMean extends UserDefinedAggregateFunction {\n  *   // This is the input fields for your aggregate function.\n  *   override def inputSchema: org.apache.spark.sql.types.StructType =\n  *     StructType(StructField(\"value\", DoubleType) :: Nil)\n  *\n  *   // This is the internal fields you keep for computing your aggregate.\n  *   override def bufferSchema: StructType = StructType(\n  *     StructField(\"count\", LongType) ::\n  *     StructField(\"product\", DoubleType) :: Nil\n  *   )\n  *\n  *   // This is the output type of your aggregatation function.\n  *   override def dataType: DataType = DoubleType\n  *\n  *   override def deterministic: Boolean = true\n  *\n  *   // This is the initial value for your buffer schema.\n  *   override def initialize(buffer: MutableAggregationBuffer): Unit = {\n  *     buffer(0) = 0L\n  *     buffer(1) = 1.0\n  *   }\n  *\n  *   // This is how to update your buffer schema given an input.\n  *   override def update(buffer: MutableAggregationBuffer, input: Row): Unit = {\n  *     buffer(0) = buffer.getAs[Long](0) + 1\n  *     buffer(1) = buffer.getAs[Double](1) * input.getAs[Double](0)\n  *   }\n  *\n  *   // This is how to merge two objects with the bufferSchema type.\n  *   override def merge(buffer1: MutableAggregationBuffer, buffer2: Row): Unit = {\n  *     buffer1(0) = buffer1.getAs[Long](0) + buffer2.getAs[Long](0)\n  *     buffer1(1) = buffer1.getAs[Double](1) * buffer2.getAs[Double](1)\n  *   }\n  *\n  *   // This is where you output the final value, given the final value of your bufferSchema.\n  *   override def evaluate(buffer: Row): Any = {\n  *     math.pow(buffer.getDouble(1), 1.toDouble / buffer.getLong(0))\n  *   }\n  * }\n  *\n  */\n\n\nobject UDAFs {\n  /**\n    * Registers UDAFs with Spark SQL\n    */\n  def registerUDAFs(spark: SparkSession): Unit = {\n    /**\n      * Example:\n      *\n      * spark.udf.register(\"gm\", GeometricMean)\n      *\n      */\n\n\n  }\n}\n"
    },
    "configuration" : {
      "common" : {
        "type" : "record",
        "fields" : [ {
          "name" : "Subgraph_0",
          "kind" : {
            "type" : "record",
            "fields" : [ ]
          },
          "optional" : false,
          "isWorkflowNodeConfiguration" : true,
          "isReferenced" : false
        }, {
          "name" : "Subgraph_0_1",
          "kind" : {
            "type" : "record",
            "fields" : [ ]
          },
          "optional" : false,
          "isWorkflowNodeConfiguration" : true,
          "isReferenced" : false
        } ]
      },
      "oldCommon" : {
        "type" : "record",
        "fields" : [ ]
      },
      "fabrics" : { },
      "instances" : { },
      "selected" : "default",
      "nonEditable" : [ ],
      "isSubscribedPipelineWithPipelineConfigs" : false
    },
    "sparkConf" : [ ],
    "hadoopConf" : [ ],
    "codeMode" : "sparse",
    "buildSystem" : "maven",
    "externalDependencies" : [ ],
    "dependentProjectExternalDependencies" : [ {
      "projectUID" : "12651",
      "projectName" : "ProphecySparkBasicsScala",
      "externalDependencies" : [ ]
    }, {
      "projectUID" : "12652",
      "projectName" : "ProphecyWarehouseScala",
      "externalDependencies" : [ ]
    } ],
    "isImported" : false,
    "interimMode" : "Full",
    "interimModeEnabled" : true,
    "visualCodeInterimMode" : "Disabled",
    "recordsLimit" : {
      "enabled" : false,
      "value" : 1000
    },
    "topLevelPackage" : "io.prophecy.pipelines.testscalapipelinegit",
    "configurationVersion" : "v2"
  },
  "connections" : [ ],
  "processes" : {
    "cRTIivvzHtcyBYOTTR6qf$$Fz6V5v3VAhpbd18_AmZ_g" : {
      "id" : "cRTIivvzHtcyBYOTTR6qf$$Fz6V5v3VAhpbd18_AmZ_g",
      "component" : "Subgraph",
      "metadata" : {
        "label" : "Subgraph_0",
        "slug" : "Subgraph_0",
        "x" : -660,
        "y" : -220,
        "phase" : 0,
        "cache" : false,
        "detailedStats" : false,
        "isImported" : false
      },
      "ports" : {
        "inputs" : [ ],
        "outputs" : [ {
          "id" : "rYw2gZgVIjoeBWCNtkEP7$$dE5W4Km_641ALQvQM06Lm",
          "slug" : "out0"
        } ],
        "selectedInputFields" : [ ],
        "isCustomOutputSchema" : false,
        "autoUpdateOnRun" : false
      },
      "properties" : { },
      "connections" : [ {
        "id" : "XgsLiPfmbU3oQ2CzR30U2",
        "source" : "Lhj3dPD1TpGtis6y8RGT3$$omYR9do2BOxo3NHDKh3kq",
        "sourcePort" : "LcCdKwl6ilm977V6XLaMO$$OX9zsDG38ZS9Ew05m_OYy",
        "target" : "cRTIivvzHtcyBYOTTR6qf$$Fz6V5v3VAhpbd18_AmZ_g",
        "targetPort" : "rYw2gZgVIjoeBWCNtkEP7$$dE5W4Km_641ALQvQM06Lm"
      } ],
      "processes" : {
        "Lhj3dPD1TpGtis6y8RGT3$$omYR9do2BOxo3NHDKh3kq" : {
          "id" : "Lhj3dPD1TpGtis6y8RGT3$$omYR9do2BOxo3NHDKh3kq",
          "component" : "Script",
          "metadata" : {
            "label" : "script_1",
            "slug" : "script_1",
            "x" : -640,
            "y" : -200,
            "phase" : 0,
            "cache" : false,
            "detailedStats" : false,
            "isImported" : false
          },
          "ports" : {
            "inputs" : [ ],
            "outputs" : [ {
              "id" : "LcCdKwl6ilm977V6XLaMO$$OX9zsDG38ZS9Ew05m_OYy",
              "slug" : "out0",
              "schema" : {
                "type" : "struct",
                "fields" : [ ]
              },
              "isStreaming" : false
            } ],
            "selectedInputFields" : [ ],
            "isCustomOutputSchema" : true,
            "autoUpdateOnRun" : true
          },
          "properties" : {
            "script" : "out0 = null",
            "scriptMethodHeader" : "def apply(spark: SparkSession): DataFrame = {",
            "scriptMethodFooter" : "    out0\n}"
          }
        }
      }
    },
    "9yiekUoPFYWmH6Hm6vSw6$$IqVGept0ODm-ufkarcxri" : {
      "id" : "9yiekUoPFYWmH6Hm6vSw6$$IqVGept0ODm-ufkarcxri",
      "component" : "Subgraph",
      "metadata" : {
        "label" : "Subgraph_0_1",
        "slug" : "Subgraph_0_1",
        "x" : -960,
        "y" : -440,
        "phase" : 0,
        "cache" : false,
        "detailedStats" : false,
        "isImported" : false
      },
      "ports" : {
        "inputs" : [ ],
        "outputs" : [ {
          "id" : "TZ1-7Qpe-Bc58-B11Nck1$$bi-bZY6dNa3Va_PT_j_Rr",
          "slug" : "out0"
        } ],
        "selectedInputFields" : [ ],
        "isCustomOutputSchema" : false,
        "autoUpdateOnRun" : false
      },
      "properties" : {
        "externalId" : "subgraphs/pubSub1",
        "name" : "pubSub1",
        "packageName" : "com.test"
      },
      "connections" : [ {
        "id" : "E5FdtMnkDQ3YiNFHIRzFM",
        "source" : "EGD9tmjMJtZrnCRWHZO_1$$cXBX5yNQiJByrKenfO79g",
        "sourcePort" : "WKUjZW-n-UTJ_vYKPbgef$$p7IuFzH-l1eirSpnGEzTi",
        "target" : "9yiekUoPFYWmH6Hm6vSw6$$IqVGept0ODm-ufkarcxri",
        "targetPort" : "TZ1-7Qpe-Bc58-B11Nck1$$bi-bZY6dNa3Va_PT_j_Rr"
      } ],
      "processes" : {
        "EGD9tmjMJtZrnCRWHZO_1$$cXBX5yNQiJByrKenfO79g" : {
          "id" : "EGD9tmjMJtZrnCRWHZO_1$$cXBX5yNQiJByrKenfO79g",
          "component" : "Script",
          "metadata" : {
            "label" : "script_1_1",
            "slug" : "script_1_1",
            "x" : -394.00000000000006,
            "y" : -72.8,
            "phase" : 0,
            "cache" : false,
            "detailedStats" : false,
            "isImported" : false
          },
          "ports" : {
            "inputs" : [ ],
            "outputs" : [ {
              "id" : "WKUjZW-n-UTJ_vYKPbgef$$p7IuFzH-l1eirSpnGEzTi",
              "slug" : "out0",
              "schema" : {
                "type" : "struct",
                "fields" : [ ]
              },
              "isStreaming" : false
            } ],
            "selectedInputFields" : [ ],
            "isCustomOutputSchema" : true,
            "autoUpdateOnRun" : true
          },
          "properties" : {
            "script" : "out0 = null",
            "scriptMethodHeader" : "def apply(spark: SparkSession): DataFrame = {",
            "scriptMethodFooter" : "    out0\n}"
          }
        }
      }
    }
  },
  "ports" : {
    "inputs" : [ ],
    "outputs" : [ ],
    "selectedInputFields" : [ ],
    "isCustomOutputSchema" : false,
    "autoUpdateOnRun" : false
  },
  "diagnostics" : [ {
    "property" : "$.workflow.processes.cRTIivvzHtcyBYOTTR6qf$$Fz6V5v3VAhpbd18_AmZ_g.processes.Lhj3dPD1TpGtis6y8RGT3$$omYR9do2BOxo3NHDKh3kq.ports.outputs",
    "range" : {
      "start" : {
        "line" : 0,
        "character" : 0
      },
      "end" : {
        "line" : 0,
        "character" : 0
      }
    },
    "severity" : 3,
    "message" : "Please infer output schema from the cluster as described [here](https://docs.prophecy.io/low-code-spark/gems/custom/script/)",
    "tags" : [ ],
    "relatedInformation" : [ ],
    "diagnosticType" : 2
  }, {
    "property" : "$.workflow.processes.9yiekUoPFYWmH6Hm6vSw6$$IqVGept0ODm-ufkarcxri.processes.EGD9tmjMJtZrnCRWHZO_1$$cXBX5yNQiJByrKenfO79g.ports.outputs",
    "range" : {
      "start" : {
        "line" : 0,
        "character" : 0
      },
      "end" : {
        "line" : 0,
        "character" : 0
      }
    },
    "severity" : 3,
    "message" : "Please infer output schema from the cluster as described [here](https://docs.prophecy.io/low-code-spark/gems/custom/script/)",
    "tags" : [ ],
    "relatedInformation" : [ ],
    "diagnosticType" : 2
  } ]
}